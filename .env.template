# =============================================================================
# PredictBot Stack - Environment Configuration Template
# =============================================================================
# Copy this file to .env and fill in your actual values
# NEVER commit .env to version control!
# =============================================================================

# -----------------------------------------------------------------------------
# POLYMARKET CONFIGURATION
# -----------------------------------------------------------------------------
# Your Ethereum wallet private key (0x... format) for Polymarket trading
# This wallet should hold USDC on Polygon and some MATIC for gas
POLY_PRIVATE_KEY=0x_your_private_key_here

# Polygon RPC endpoint (Infura, Alchemy, or other provider)
# Example: https://polygon-mainnet.infura.io/v3/YOUR_PROJECT_ID
POLY_RPC_URL=https://polygon-mainnet.infura.io/v3/YOUR_INFURA_PROJECT_ID

# Optional: Backup RPC URL for failover
POLY_RPC_URL_BACKUP=

# -----------------------------------------------------------------------------
# KALSHI CONFIGURATION
# -----------------------------------------------------------------------------
# Kalshi API credentials (obtain from Kalshi dashboard -> API Access)
KALSHI_API_KEY=your_kalshi_api_key
KALSHI_API_SECRET=your_kalshi_api_secret

# Kalshi API base URL (production)
KALSHI_API_URL=https://trading-api.kalshi.com/trade-api/v2

# -----------------------------------------------------------------------------
# MANIFOLD CONFIGURATION
# -----------------------------------------------------------------------------
# Manifold API key (obtain from Manifold profile -> API settings)
MANIFOLD_API_KEY=your_manifold_api_key

# Your Manifold username (for bot identification)
MANIFOLD_USERNAME=your_manifold_username

# Manifold API base URL
MANIFOLD_API_URL=https://api.manifold.markets/v0

# -----------------------------------------------------------------------------
# PREDICTIT CONFIGURATION
# -----------------------------------------------------------------------------
# PredictIt API token or session cookie
# Note: PredictIt has limited API support; may require manual token refresh
PREDICTIT_API_TOKEN=your_predictit_token

# Alternative: Username/password (less secure, use token if possible)
PREDICTIT_USERNAME=
PREDICTIT_PASSWORD=

# PredictIt API base URL
PREDICTIT_API_URL=https://www.predictit.org/api

# -----------------------------------------------------------------------------
# OPENROUTER CONFIGURATION (Primary LLM Provider)
# -----------------------------------------------------------------------------
# OpenRouter provides unified access to 100+ LLM models through a single API
# Benefits: Single API key, automatic fallback, unified cost tracking
# Obtain your API key from: https://openrouter.ai/keys

# OpenRouter API key (required for cloud LLM access)
OPENROUTER_API_KEY=sk-or-v1-your_openrouter_api_key_here

# Enable/disable OpenRouter (set to false to use legacy providers)
OPENROUTER_ENABLED=true

# OpenRouter base URL (default is fine for most users)
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# Monthly budget limit for OpenRouter (USD)
OPENROUTER_MONTHLY_BUDGET=100

# Request timeout in seconds
OPENROUTER_TIMEOUT=60

# -----------------------------------------------------------------------------
# MODEL CONFIGURATION PER TASK TYPE
# -----------------------------------------------------------------------------
# Override default models for specific task types
# Format: provider/model-name (e.g., anthropic/claude-3.5-sonnet)
# See available models at: https://openrouter.ai/models

# Fast tasks (news sentiment, quick decisions) - prioritize speed
LLM_MODEL_FAST=anthropic/claude-3-haiku

# Analysis tasks (market analysis) - balance speed and quality
LLM_MODEL_ANALYSIS=anthropic/claude-3.5-sonnet

# Reasoning tasks (forecasting, complex analysis) - prioritize accuracy
LLM_MODEL_REASONING=anthropic/claude-3.5-sonnet

# Critique tasks (adversarial review) - use different provider to avoid bias
LLM_MODEL_CRITIQUE=meta-llama/llama-3.1-70b-instruct

# Default model for general tasks
LLM_MODEL_DEFAULT=anthropic/claude-3.5-sonnet

# -----------------------------------------------------------------------------
# OLLAMA CONFIGURATION (Local Fallback)
# -----------------------------------------------------------------------------
# Ollama provides local LLM inference for privacy, cost savings, and offline use
# Used as fallback when OpenRouter is unavailable

# Enable/disable Ollama local inference
OLLAMA_ENABLED=true

# Ollama server URL
# Use 'ollama' as host when running in Docker, 'localhost' for local dev
OLLAMA_BASE_URL=http://ollama:11434

# Default Ollama model (must be pulled first: ollama pull llama3.1:8b)
OLLAMA_DEFAULT_MODEL=llama3.1:8b

# -----------------------------------------------------------------------------
# LEGACY LLM PROVIDERS (Deprecated - Use OpenRouter Instead)
# -----------------------------------------------------------------------------
# These are kept for backward compatibility but disabled when OpenRouter is enabled
# To use legacy providers, set OPENROUTER_ENABLED=false

# OpenAI API key (deprecated - use OpenRouter)
OPENAI_API_KEY=

# Anthropic API key (deprecated - use OpenRouter)
ANTHROPIC_API_KEY=

# Groq API key (deprecated - use OpenRouter)
GROQ_API_KEY=

# xAI API key (deprecated)
XAI_API_KEY=

# Legacy monthly budget limits (only used if OPENROUTER_ENABLED=false)
OPENAI_MONTHLY_BUDGET=50
ANTHROPIC_MONTHLY_BUDGET=30
GROQ_MONTHLY_BUDGET=10

# -----------------------------------------------------------------------------
# AI ORCHESTRATOR CONFIGURATION
# -----------------------------------------------------------------------------
# AI Orchestrator service settings
AI_ORCHESTRATOR_PORT=8081

# Maximum monthly AI API spend limit in USD (0 = unlimited)
# This is a global limit across all providers
AI_MONTHLY_BUDGET=100.0

# -----------------------------------------------------------------------------
# NEWS FEED CONFIGURATION
# -----------------------------------------------------------------------------
# News API keys for market-relevant news aggregation
# Used by the news_sentiment agent for real-time news analysis

# NewsAPI.org API key (obtain from newsapi.org)
# Free tier: 100 requests/day, paid plans available
NEWSAPI_KEY=

# Alpha Vantage API key (obtain from alphavantage.co)
# Provides financial news with sentiment analysis
ALPHA_VANTAGE_KEY=

# News feed settings
NEWS_CACHE_TTL=300
NEWS_MAX_ARTICLES=50
NEWS_LOOKBACK_HOURS=24

# -----------------------------------------------------------------------------
# POLYSEER CONFIGURATION (Optional)
# -----------------------------------------------------------------------------
# Valyu API key for Polyseer research assistant
# Obtain from valyu.ai platform
VALYU_API_KEY=your_valyu_api_key

# Polyseer self-hosted mode
POLYSEER_ENABLED=false
POLYSEER_PORT=3001

# -----------------------------------------------------------------------------
# MCP SERVER CONFIGURATION
# -----------------------------------------------------------------------------
# Model Context Protocol server settings
MCP_SERVER_PORT=3000
MCP_SERVER_HOST=0.0.0.0

# -----------------------------------------------------------------------------
# SYSTEM CONFIGURATION
# -----------------------------------------------------------------------------
# Dry run mode - set to 1 to simulate trades without executing
# ALWAYS start with DRY_RUN=1 for testing!
DRY_RUN=1

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log output format (json, text)
LOG_FORMAT=text

# Timezone for logging and scheduling
TIMEZONE=UTC

# -----------------------------------------------------------------------------
# STRATEGY ENABLE/DISABLE FLAGS
# -----------------------------------------------------------------------------
# Set to 1 to enable, 0 to disable each strategy module
ENABLE_ARB=1
ENABLE_MM_POLYMARKET=1
ENABLE_MM_MANIFOLD=1
ENABLE_SPIKE=1
ENABLE_AI=1

# -----------------------------------------------------------------------------
# RISK MANAGEMENT CONFIGURATION
# -----------------------------------------------------------------------------
# Maximum daily loss before auto-shutdown (in USD)
MAX_DAILY_LOSS=100.0

# Maximum total position across all platforms (in USD)
MAX_TOTAL_POSITION=1000.0

# Circuit breaker - halt trading after N consecutive failures
CIRCUIT_BREAKER_THRESHOLD=5

# Circuit breaker cooldown period (seconds)
CIRCUIT_BREAKER_COOLDOWN=300

# -----------------------------------------------------------------------------
# ARBITRAGE MODULE CONFIGURATION
# -----------------------------------------------------------------------------
# Minimum profit percentage to execute arbitrage (0.02 = 2%)
ARB_MIN_PROFIT=0.02

# Maximum capital per arbitrage trade (USD)
ARB_MAX_TRADE_SIZE=300

# Include PredictIt in arbitrage scanning
ARB_INCLUDE_PREDICTIT=false

# -----------------------------------------------------------------------------
# MARKET MAKING CONFIGURATION
# -----------------------------------------------------------------------------
# Polymarket market maker settings
MM_POLY_SPREAD_BPS=500
MM_POLY_ORDER_SIZE=50
MM_POLY_INVENTORY_LIMIT=500

# Manifold market maker settings
MM_MANIFOLD_ORDER_SIZE=100

# -----------------------------------------------------------------------------
# SPIKE TRADING CONFIGURATION
# -----------------------------------------------------------------------------
# Price movement threshold to trigger spike detection (0.05 = 5%)
SPIKE_SENSITIVITY=0.05

# Strategy: mean_reversion, momentum, or hybrid
SPIKE_STRATEGY=mean_reversion

# Maximum bet size for spike trades (USD)
SPIKE_MAX_SIZE=100

# Cooldown between spike trades on same market (seconds)
SPIKE_COOLDOWN=60

# -----------------------------------------------------------------------------
# AI TRADING CONFIGURATION
# -----------------------------------------------------------------------------
# Market scan interval (seconds)
AI_SCAN_INTERVAL=300

# Minimum confidence threshold to execute trade (0.6 = 60%)
AI_CONFIDENCE_THRESHOLD=0.6

# Maximum bet size for AI trades (USD)
AI_MAX_BET=100

# -----------------------------------------------------------------------------
# NOTIFICATION CONFIGURATION (Optional)
# -----------------------------------------------------------------------------
# Slack webhook for alerts
SLACK_WEBHOOK_URL=

# Discord webhook for alerts
DISCORD_WEBHOOK_URL=

# Email alerts (requires SMTP configuration)
ALERT_EMAIL=
SMTP_HOST=
SMTP_PORT=587
SMTP_USER=
SMTP_PASSWORD=

# -----------------------------------------------------------------------------
# DATABASE CONFIGURATION
# -----------------------------------------------------------------------------
# PostgreSQL with TimescaleDB for historical data and time-series
# Generate a secure password: openssl rand -base64 32
POSTGRES_PASSWORD=your_secure_postgres_password_here

# PostgreSQL connection URL (used by Prisma and application services)
# Note: Use 'postgres' as host when running in Docker, 'localhost' for local dev
DATABASE_URL=postgresql://predictbot:${POSTGRES_PASSWORD}@postgres:5432/predictbot

# PostgreSQL host (for direct connections)
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=predictbot
POSTGRES_DB=predictbot

# -----------------------------------------------------------------------------
# REDIS CONFIGURATION
# -----------------------------------------------------------------------------
# Redis for real-time state, caching, and pub/sub
# Use 'redis' as host when running in Docker, 'localhost' for local dev
REDIS_URL=redis://redis:6379

# Redis host (for direct connections)
REDIS_HOST=redis
REDIS_PORT=6379

# Optional: Redis password (uncomment if using authenticated Redis)
# REDIS_PASSWORD=your_redis_password

# -----------------------------------------------------------------------------
# LEGACY DATABASE (Deprecated - kept for backward compatibility)
# -----------------------------------------------------------------------------
# SQLite database path for local development/testing only
# Production should use PostgreSQL above
DATABASE_PATH=./data/predictbot.db

# -----------------------------------------------------------------------------
# MONITORING CONFIGURATION
# -----------------------------------------------------------------------------
# Grafana admin credentials
# Change these in production!
GRAFANA_USER=admin
GRAFANA_PASSWORD=your_secure_grafana_password

# Prometheus data retention period
PROMETHEUS_RETENTION=15d

# Loki log retention period
LOKI_RETENTION=30d

# Enable/disable monitoring stack
MONITORING_ENABLED=true

# Monitoring service ports (change if conflicts exist)
GRAFANA_PORT=3002
PROMETHEUS_PORT=9090
LOKI_PORT=3100

# -----------------------------------------------------------------------------
# ADMIN PORTAL CONFIGURATION
# -----------------------------------------------------------------------------
# NextAuth.js secret for session encryption
# Generate with: openssl rand -base64 32
NEXTAUTH_SECRET=your_nextauth_secret_here

# NextAuth.js URL (must match the admin portal URL)
NEXTAUTH_URL=http://localhost:3003

# Admin portal credentials
# Change these in production!
ADMIN_USERNAME=admin
ADMIN_PASSWORD=your_secure_admin_password

# Admin portal port
ADMIN_PORTAL_PORT=3003

# -----------------------------------------------------------------------------
# DOCKER CONFIGURATION
# -----------------------------------------------------------------------------
# Container resource limits
CONTAINER_MEMORY_LIMIT=512m
CONTAINER_CPU_LIMIT=1.0
